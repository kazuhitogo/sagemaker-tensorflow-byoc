{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker - Bring Your Own Container¶\n",
    "### 学習用インスタンスでの学習\n",
    "ここでは TensorFlow を使ったサンプルコードを題材に、Amazon SageMaker で独自コンテナを用いた機械学習モデルの学習方法を順を追って説明します。トレーニングスクリプトは既に SageMaker 向けに書き換えられた形で準備され、その上で、独自の学習用コンテナを活用します。 トレーニングスクリプトを SageMaker 向けに書き換える際は [Bring Your Own Model ハンズオンワークショップ](https://github.com/aws-samples/amazon-sagemaker-examples-jp/tree/master/workshop/lab_bring-your-own-model) をご参考に下さい。\n",
    "\n",
    "また本ハンズオンで活用するデータは、[Bring Your Own Container のためのデータ準備](https://github.com/tkazusa/data_prep.ipynb)をお使い下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sagemaker-experiments\n",
    "!{sys.executable} -m pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t sm-tf-nightly-gpu container/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習用インスタンスを用いた学習\n",
    "### ECR への Docker イメージの登録\n",
    "build した Docker イメージを Docker コンテナレジストリである Amazon ECR へ登録することで、SageMaker の学習時に活用できるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# boto3の機能を使ってリポジトリ名に必要な情報を取得する\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "tag = ':latest'\n",
    "\n",
    "ecr_repository = 'sm-tf-nightly-gpu'\n",
    "image_uri = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account_id, region, ecr_repository + tag)\n",
    "\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    " \n",
    "# リポジトリの作成\n",
    "# すでにある場合はこのコマンドは必要ない\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    " \n",
    "!docker build -t {ecr_repository} .\n",
    "!docker tag {ecr_repository + tag} $image_uri\n",
    "!docker push $image_uri\n",
    "\n",
    "print('コンテナは {} へ登録されています。'.format(image_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "from smexperiments.experiment import Experiment\n",
    "\n",
    "boto3_sess = boto3.Session()\n",
    "sm = boto3_sess.client('sagemaker')\n",
    "\n",
    "tf_experiment = Experiment.create(\n",
    "    experiment_name=f\"tensorflow-byoc-{int(time.time())}\", \n",
    "    description=\"tensorflow experiments\", \n",
    "    sagemaker_boto_client=sm)\n",
    "\n",
    "print(tf_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU を使った学習インスタンスでの学習\n",
    "登録された Docker イメージと、S3 へアップロードされたデータを用いて学習を行います。\n",
    "ここでは Optimizer を 'Adam' と 'SGD' とで変更した際の実験管理を行っています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket = '<your bucket name>'\n",
    "output_path = 's3://{}/output'.format(bucket)\n",
    "data_path = {'train': 's3://{}/data'.format(bucket)}\n",
    "\n",
    "metric_definitions = [{'Name': 'loss',\n",
    "                       'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "                      {'Name': 'accuracy',\n",
    "                       'Regex': 'accuracy: ([0-9\\\\.]+)'}]\n",
    "\n",
    "trial_name_map = {}\n",
    "\n",
    "optimizers = ['adam', 'sgd']\n",
    "\n",
    "for i, optimizer in enumerate(optimizers):\n",
    "    # Trial の作成\n",
    "    trial_name = f'tf-training-job-{optimizer}-{int(time.time())}'\n",
    "    print(trial_name)\n",
    "    \n",
    "    \n",
    "    tf_trial = Trial.create(\n",
    "        trial_name=trial_name, \n",
    "        experiment_name=tf_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm,\n",
    "    )\n",
    "    trial_name_map[optimizer] = trial_name\n",
    "    \n",
    "    # Estimator の作成とfit。\n",
    "    hyperparameters = {'batch_size': 64,'epochs': 1, 'optimizer': optimizer}\n",
    "    estimator = Estimator(image_name=image_uri,\n",
    "                          role=role,\n",
    "                          hyperparameters=hyperparameters,\n",
    "                          train_instance_count=1,\n",
    "                          train_instance_type='ml.p2.xlarge',\n",
    "                          output_path=output_path,\n",
    "                          metric_definitions=metric_definitions,\n",
    "                          enable_sagemaker_metrics=True,)\n",
    "    \n",
    "    tf_training_job_name = \"tf-job-{}\".format(int(time.time()))\n",
    "    \n",
    "    estimator.fit(data_path,\n",
    "                 job_name=tf_training_job_name,\n",
    "                  \n",
    "                 experiment_config={\n",
    "                     'TrialName': tf_trial.trial_name,\n",
    "                     'TrialComponentDisplayName': 'Training',\n",
    "                 },\n",
    "                  \n",
    "                 wait=False)\n",
    "    \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import Session\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "sess = boto3.Session()\n",
    "\n",
    "search_expression = {\n",
    "    \"Filters\":[\n",
    "        {\n",
    "            \"Name\": \"DisplayName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": \"Training\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=Session(sess, sm), \n",
    "    experiment_name=tf_experiment.experiment_name,\n",
    "    search_expression=search_expression,\n",
    "    sort_by=\"metrics.accuracy.max\",\n",
    "    sort_order=\"Descending\",\n",
    "    metric_names=['accuracy'],\n",
    "    parameter_names=['optimizer']\n",
    ")\n",
    "\n",
    "analytic_table = trial_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytic_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
